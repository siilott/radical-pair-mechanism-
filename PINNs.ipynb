{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Define the PINN model\n",
    "class QuantumPINN(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(QuantumPINN, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(1, 128)\n",
    "        self.hidden_layer2 = nn.Linear(128, 128)\n",
    "        self.output_layer = nn.Linear(128, dim * dim * 2)  # Output is the real and imaginary parts of rho\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.reshape(-1, 1)  # Input is time\n",
    "        x = torch.relu(self.hidden_layer1(t))\n",
    "        x = torch.relu(self.hidden_layer2(x))\n",
    "        output = self.output_layer(x)\n",
    "        real_part = output[:, :dim * dim].reshape(-1, dim, dim)\n",
    "        imag_part = output[:, dim * dim:].reshape(-1, dim, dim)\n",
    "        rho = torch.complex(real_part, imag_part)\n",
    "        return rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loss(pinn_model, Hamiltonian):\n",
    "    def loss_fn(t):\n",
    "        rho_pred = pinn_model(t)  # Predict rho(t)\n",
    "        \n",
    "        # Separate real and imaginary parts of the predicted rho\n",
    "        rho_real = rho_pred.real\n",
    "        rho_imag = rho_pred.imag\n",
    "\n",
    "        # Compute time derivatives using autograd (for both real and imaginary parts)\n",
    "        rho_t_real = torch.autograd.grad(rho_real.sum(), t, create_graph=True)[0]\n",
    "        rho_t_imag = torch.autograd.grad(rho_imag.sum(), t, create_graph=True)[0]\n",
    "        \n",
    "        # Compute the commutator: [H, rho]\n",
    "        commutator_real = - (Hamiltonian @ rho_real - rho_real @ Hamiltonian) + 1j * (Hamiltonian @ rho_imag - rho_imag @ Hamiltonian)\n",
    "        commutator_imag = - (Hamiltonian @ rho_imag - rho_imag @ Hamiltonian) - 1j * (Hamiltonian @ rho_real - rho_real @ Hamiltonian)\n",
    "\n",
    "        # Loss is the MSE between the time derivative and the commutator (real and imaginary parts separately)\n",
    "        loss_real = torch.mean((rho_t_real - commutator_real.real)**2)\n",
    "        loss_imag = torch.mean((rho_t_imag - commutator_imag.imag)**2)\n",
    "        \n",
    "        return loss_real + loss_imag\n",
    "    \n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import functools\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import qutip as qt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary maps string keys ('x', 'y', 'z', 'p', 'm', 'i') to functions that generate spin operators for a given dimension dim.\n",
    "opstr2fun = {'x': lambda dim: qt.spin_Jx((dim-1)/2),\n",
    "             'y': lambda dim: qt.spin_Jy((dim-1)/2),\n",
    "             'z': lambda dim: qt.spin_Jz((dim-1)/2),\n",
    "             'p': lambda dim: qt.spin_Jp((dim-1)/2),\n",
    "             'm': lambda dim: qt.spin_Jm((dim-1)/2),\n",
    "             'i': qt.identity}\n",
    "# Initializes ops as a list of identity matrices for each dimension in dims. Iterates over specs to replace the identity matrix at the specified index with the corresponding spin operator. Returns the tensor product of the operators in ops using qt.tensor.\n",
    "def mkSpinOp(dims, specs):\n",
    "    ops = [qt.identity(d) for d in dims]\n",
    "    for ind, opstr in specs:\n",
    "        ops[ind] = ops[ind] * opstr2fun[opstr](dims[ind])\n",
    "    return qt.tensor(ops)\n",
    "# Constructs a Hamiltonian for a single spin system with interactions along the x, y, and z axes.\n",
    "def mkH1(dims, ind, parvec):\n",
    "    axes = ['x', 'y', 'z']\n",
    "    # Creates a list of spin operators weighted by the corresponding parameters in parvec (ignores zero parameters). Uses functools.reduce to sum these weighted spin operators.\n",
    "    return functools.reduce(lambda a, b: a + b, \n",
    "               [v * mkSpinOp(dims, [(ind,ax)]) for v, ax in zip(parvec, axes) if v!=0])\n",
    "# Constructs a Hamiltonian for the interaction between two spin systems with interaction terms along all combinations of x, y, and z axes.\n",
    "def mkH12(dims, ind1, ind2, parmat):\n",
    "    axes = ['x', 'y', 'z']\n",
    "    ops = []\n",
    "    # Iterates over all combinations of the x, y, and z axes for the two spins. For each non-zero element in parmat, adds the corresponding spin-spin interaction term to the empty list ops.\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if parmat[i,j] != 0:\n",
    "                ops.append(parmat[i,j] * mkSpinOp(dims, [(ind1,axes[i]), (ind2,axes[j])]))\n",
    "    return functools.reduce(lambda a, b: a + b, ops) # Uses functools.reduce to sum these interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t(154.56635855661784+0j)\n",
      "  (3, 0)\t(4.39822971502571+0j)\n",
      "  (6, 0)\t(4.39822971502571+0j)\n",
      "  (4, 1)\t(4.39822971502571+0j)\n",
      "  (6, 1)\t(-11.551495639211753+0j)\n",
      "  (7, 1)\t(4.39822971502571+0j)\n",
      "  (2, 2)\t(-154.56635855661784+0j)\n",
      "  (5, 2)\t(4.39822971502571+0j)\n",
      "  (7, 2)\t(-11.551495639211753+0j)\n",
      "  (8, 2)\t(4.39822971502571+0j)\n",
      "  (0, 3)\t(4.39822971502571+0j)\n",
      "  (3, 3)\t(154.56635855661784+0j)\n",
      "  (9, 3)\t(4.39822971502571+0j)\n",
      "  (1, 4)\t(4.39822971502571+0j)\n",
      "  (9, 4)\t(-11.551495639211753+0j)\n",
      "  (10, 4)\t(4.39822971502571+0j)\n",
      "  (2, 5)\t(4.39822971502571+0j)\n",
      "  (5, 5)\t(-154.56635855661784+0j)\n",
      "  (10, 5)\t(-11.551495639211753+0j)\n",
      "  (11, 5)\t(4.39822971502571+0j)\n",
      "  (0, 6)\t(4.39822971502571+0j)\n",
      "  (1, 6)\t(-11.551495639211753+0j)\n",
      "  (6, 6)\t(-154.56635855661784+0j)\n",
      "  (9, 6)\t(4.39822971502571+0j)\n",
      "  (1, 7)\t(4.39822971502571+0j)\n",
      "  (2, 7)\t(-11.551495639211753+0j)\n",
      "  (10, 7)\t(4.39822971502571+0j)\n",
      "  (2, 8)\t(4.39822971502571+0j)\n",
      "  (8, 8)\t(154.56635855661784+0j)\n",
      "  (11, 8)\t(4.39822971502571+0j)\n",
      "  (3, 9)\t(4.39822971502571+0j)\n",
      "  (4, 9)\t(-11.551495639211753+0j)\n",
      "  (6, 9)\t(4.39822971502571+0j)\n",
      "  (9, 9)\t(-154.56635855661784+0j)\n",
      "  (4, 10)\t(4.39822971502571+0j)\n",
      "  (5, 10)\t(-11.551495639211753+0j)\n",
      "  (7, 10)\t(4.39822971502571+0j)\n",
      "  (5, 11)\t(4.39822971502571+0j)\n",
      "  (8, 11)\t(4.39822971502571+0j)\n",
      "  (11, 11)\t(154.56635855661784+0j)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "b0 = 1.4 * 2*math.pi # Zeeman field strength in radians per microsecond\n",
    "A = np.diag([-2.6, -2.6, 49.2]) * 2*math.pi # Hyperfine coupling matrix (Mrad/s)\n",
    "kr = 1. # Rate constant 1/us\n",
    "tmax = 12. / kr # Maximum time us\n",
    "tlist = np.linspace(0, tmax, math.ceil(1000*tmax)) # Time points for simulation\n",
    "B0 = b0 * np.array([1,0,0]) # Magnetic field vector along x-axis\n",
    "\n",
    "dims = [2, 2, 3] # Dimensions of the system components (2 qubits, 1 spin-1 nucleus)\n",
    "dim = np.prod(dims) # Total dimension of the composite system\n",
    "Hzee = mkH1(dims, 0, B0) + mkH1(dims, 1, B0) # Zeeman Hamiltonian for two spins\n",
    "Hhfc = mkH12(dims, 0, 2, A) # Hyperfine coupling Hamiltonian\n",
    "H0 = Hzee + Hhfc # Total Hamiltonian\n",
    "\n",
    "Ps = 1/4 * mkSpinOp(dims,[]) - mkH12(dims, 0, 1, np.identity(3)) # Singlet projection operator\n",
    "\n",
    "rho0 = (Ps / Ps.tr()).full().flatten() # Initial density matrix, normalized projection operator for the singlet state.\n",
    "# Convert the Hamiltonian H0 to a scipy sparse matrix and then to a PyTorch sparse tensor\n",
    "H_scipy = H0.data.tocsc()  # Convert to a SciPy sparse CSC matrix\n",
    "\n",
    "# Extract the indices and values for the sparse tensor\n",
    "H_indices = torch.LongTensor(np.vstack([H_scipy.nonzero()[0], H_scipy.nonzero()[1]]))  # Non-zero element indices\n",
    "H_values = torch.FloatTensor(H_scipy.data)  # Non-zero values\n",
    "H_shape = H_scipy.shape  # Shape of the matrix\n",
    "\n",
    "# Convert to a PyTorch sparse tensor\n",
    "H_torch_sparse = torch.sparse_coo_tensor(H_indices, H_values, H_shape)..to(device)\n",
    "Ps = Ps.data.toarray()\n",
    "print(H_scipy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_t_collocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mgenerate_loss.<locals>.loss_fn\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     11\u001b[0m rho_t_imag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(rho_imag\u001b[38;5;241m.\u001b[39msum(), t, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Compute the commutator: [H, rho]\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m commutator_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[43mHamiltonian\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrho_real\u001b[49m \u001b[38;5;241m-\u001b[39m rho_real \u001b[38;5;241m@\u001b[39m Hamiltonian) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m (Hamiltonian \u001b[38;5;241m@\u001b[39m rho_imag \u001b[38;5;241m-\u001b[39m rho_imag \u001b[38;5;241m@\u001b[39m Hamiltonian)\n\u001b[1;32m     15\u001b[0m commutator_imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m (Hamiltonian \u001b[38;5;241m@\u001b[39m rho_imag \u001b[38;5;241m-\u001b[39m rho_imag \u001b[38;5;241m@\u001b[39m Hamiltonian) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m (Hamiltonian \u001b[38;5;241m@\u001b[39m rho_real \u001b[38;5;241m-\u001b[39m rho_real \u001b[38;5;241m@\u001b[39m Hamiltonian)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Loss is the MSE between the time derivative and the commutator (real and imaginary parts separately)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py:678\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    677\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py:592\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_sparse_matrix(other)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m other_a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other_a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other_a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Not interpretable as an array; return NotImplemented so that\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# other's __rmul__ can kick in if that's implemented.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "pinn_model = QuantumPINN(dim).to(device)\n",
    "optimizer = torch.optim.Adam(pinn_model.parameters(), lr=0.001)\n",
    "loss_fn = generate_loss(pinn_model, H)\n",
    "\n",
    "# Time points for training\n",
    "t_collocation = np.linspace(0, tmax, 1000).reshape(-1, 1)\n",
    "pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "\n",
    "# Training loop\n",
    "iterations = 5000\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(pt_t_collocation)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the evolution\n",
    "with torch.no_grad():\n",
    "    pt_t_eval = Variable(torch.from_numpy(tlist).float(), requires_grad=True).to(device)\n",
    "    rho_pred = pinn_model(pt_t_eval)\n",
    "\n",
    "# Extract the predicted singlet probability\n",
    "ps_pred = []\n",
    "for rho_t in rho_pred:\n",
    "    ps_pred.append(np.real(np.trace(Ps @ rho_t.cpu().numpy())))\n",
    "\n",
    "# Plot results\n",
    "plt.plot(tlist, ps_pred, label=\"PINN Prediction\")\n",
    "plt.plot(tlist[:1000], ps[:1000], label=\"Original ODE Solution\")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Singlet Probability')\n",
    "plt.title('Evolution of singlet probability over time for 1 spin-1 nucleus')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
